{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TumoriBenigni_Maligni.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feYVubuh9KuL"
      },
      "source": [
        "##Librerie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ef9_FUN1q_W0"
      },
      "source": [
        "###LIBRERIE \n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from google.colab import drive\n",
        "from tensorflow.python.client import device_lib\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import StandardScaler \n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras import layers, models\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras import backend\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7PSqTLt7DB5"
      },
      "source": [
        "# Inserimento dei dati\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsQ6BLusrfLz"
      },
      "source": [
        "###DATA PREPROCESSING \n",
        "drive.mount('/content/drive', force_remount = True)\n",
        "\n",
        "folder_benign_train = '/content/drive/MyDrive/Colab/train/benign'\n",
        "folder_malignant_train = '/content/drive/MyDrive/Colab/train/malignant'\n",
        "\n",
        "folder_benign_test = '/content/drive/MyDrive/Colab/test/benign'\n",
        "folder_malignant_test = '/content/drive/MyDrive/Colab/test/malignant'\n",
        "\n",
        "read = lambda imname: np.asarray(Image.open(imname).convert(\"RGB\"))\n",
        "\n",
        "# Carico le immagini di train\n",
        "ims_benign = [read(os.path.join(folder_benign_train, filename)) for filename in os.listdir(folder_benign_train)]\n",
        "X_benign = np.array(ims_benign, dtype='uint8')\n",
        "print(\"train beningi caricati\")\n",
        "ims_malignant = [read(os.path.join(folder_malignant_train, filename)) for filename in os.listdir(folder_malignant_train)]\n",
        "X_malignant = np.array(ims_malignant, dtype='uint8')\n",
        "print(\"train maligni caricati\")\n",
        "\n",
        "# Carico le immagini di test\n",
        "ims_benign = [read(os.path.join(folder_benign_test, filename)) for filename in os.listdir(folder_benign_test)]\n",
        "X_benign_test = np.array(ims_benign, dtype='uint8')\n",
        "print(\"test beningi caricati\")\n",
        "ims_malignant = [read(os.path.join(folder_malignant_test, filename)) for filename in os.listdir(folder_malignant_test)]\n",
        "X_malignant_test = np.array(ims_malignant, dtype='uint8')\n",
        "print(\"test maligni caricati\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGVkX0fSAe5Q"
      },
      "source": [
        "##Creo le Lables\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R7NLQibrf0k"
      },
      "source": [
        "\n",
        "y_benign = np.zeros(X_benign.shape[0])\n",
        "y_malignant = np.ones(X_malignant.shape[0])\n",
        "\n",
        "y_benign_test = np.zeros(X_benign_test.shape[0])\n",
        "y_malignant_test = np.ones(X_malignant_test.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MozVlopnAoa9"
      },
      "source": [
        "##Merge and Shuffle\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vup3r6ywAval"
      },
      "source": [
        "X_train = np.concatenate((X_benign, X_malignant), axis = 0)\n",
        "y_train = np.concatenate((y_benign, y_malignant), axis = 0)\n",
        "\n",
        "X_test = np.concatenate((X_benign_test, X_malignant_test), axis = 0)\n",
        "y_test = np.concatenate((y_benign_test, y_malignant_test), axis = 0)\n",
        "\n",
        "\n",
        "#Shuffle\n",
        "s = np.arange(X_train.shape[0])\n",
        "np.random.shuffle(s)\n",
        "X_train = X_train[s]\n",
        "y_train = y_train[s]\n",
        "\n",
        "s = np.arange(X_test.shape[0])\n",
        "np.random.shuffle(s)\n",
        "X_test = X_test[s]\n",
        "y_test = y_test[s]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eifnYTDnBDRq"
      },
      "source": [
        "##Visualizzo le immagini"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4KSqpSoBFml"
      },
      "source": [
        "fig=plt.figure(figsize=(17, 8))\n",
        "columns = 8\n",
        "rows = 5\n",
        "\n",
        "for i in range(1, columns*rows +1):\n",
        "    ax = fig.add_subplot(rows, columns, i)\n",
        "    if y_train[i] == 0:\n",
        "        ax.title.set_text('Benign')\n",
        "    else:\n",
        "        ax.title.set_text('Malignant')\n",
        "    plt.imshow(X_train[i], interpolation='nearest')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PFlEqYKBJBU"
      },
      "source": [
        "##Lables-->Categorical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KPgAGDyBSCk"
      },
      "source": [
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=2)\n",
        "y_test =tf.keras.utils.to_categorical(y_test, num_classes=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dA_e53UqBXri"
      },
      "source": [
        "##Normalizzazione"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1AI19mSBiwV"
      },
      "source": [
        "X_train = X_train/255\n",
        "X_test = X_test/255\n",
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4iq4jP9BlbU"
      },
      "source": [
        "##Modello"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ru0kKrLDBsoM"
      },
      "source": [
        "#in optin da provare con rmsprop , adam e in activation_Dense con sigmoid , softmax\n",
        "def Addestramento(input_shape, lr, numclassi, optim, activation_Dense): \n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3,3), padding = 'same',activation = 'relu', input_shape = input_shape,kernel_initializer='glorot_uniform'))\n",
        "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
        "    model.add(Dropout(0.40))#metto questo stato di dropout per evitare un overfitting della rete \n",
        "    model.add(layers.Conv2D(64, (3,3), padding = 'same' ,activation = 'relu', kernel_initializer='glorot_uniform'))\n",
        "    model.add(MaxPool2D(2,2))\n",
        "    model.add(Dropout(0.40))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(Dense(128, activation = 'relu'))\n",
        "    model.add(Dense(numclassi, activation='softmax'))\n",
        "    #Scegli l'ottimizzatore\n",
        "    if optim == 'rmsprop':\n",
        "        optimizer = RMSprop(lr=lr)\n",
        "    else:\n",
        "        optimizer = Adam(lr=lr)\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(optimizer = optimizer , loss = \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNp9m9UABwIJ"
      },
      "source": [
        "##Addestramento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4_yijf5B5pX"
      },
      "source": [
        "model = Addestramento((224,224,3), 1e-5, 2,'relu', 'adam')\n",
        "\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=5,  verbose=1, factor=0.5,  min_lr=1e-7)\n",
        "\n",
        "epochs = 1\n",
        "batch_size = 64\n",
        "\n",
        "history = model.fit(X_train, y_train, validation_split=0.2, epochs= epochs , batch_size= batch_size,callbacks=[learning_rate_reduction], verbose=1)\n",
        "#Lista di tutta la storia fatta dai dati \n",
        "print(history.history.keys())\n",
        "# storia accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "#storia loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwh9eUlcNlXo"
      },
      "source": [
        "backend.clear_session()\n",
        "del model\n",
        "del history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dCoJ6NQY_gt"
      },
      "source": [
        "##K-fold\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9c51f4wZDbR"
      },
      "source": [
        "# Merge inputs and targets\n",
        "inputs = np.concatenate((X_train, X_test), axis=0)\n",
        "targets = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "#3 k fold\n",
        "kfold = KFold(n_splits=3, shuffle=True)\n",
        "print(f'values kfold = {kfold}')\n",
        "\n",
        "#score container\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "fold_no = 1\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "\n",
        "    model = Addestramento((224,224,3), 1e-5, 2,'relu', 'adam')\n",
        "    print(\"rete caricata\")\n",
        "    \n",
        "    #Addestro il modello su una parte dei dati di train\n",
        "    model.fit(X_train[train], y_train[train], epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "    print('fine addestramento rete')\n",
        "\n",
        "    # provo il modello sui dati di test rimanenti\n",
        "    scores = model.evaluate(X_train[test], y_train[test], verbose=1)\n",
        "    print(f'score ottenuto dalla rete{scores}')\n",
        "    \n",
        "    #score del modello in percentuale\n",
        "    scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
        "    print(f'Score per fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "    acc_per_fold.append(scores[1] * 100)\n",
        "    loss_per_fold.append(scores[0])\n",
        "\n",
        "    # Increase fold number\n",
        "    fold_no = fold_no + 1\n",
        "    del model\n",
        "\n",
        "#Media degli score\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Media degli scores per tutte le folds:')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}